(parkinson) xxx@xxx:~/xxx/dream_parkinsons/py/dream_parkinsons/appsâŸ« python train_merged.py --dataset="/xxx/" --output_directory="/xxx/" --fraction_of_data_set=0.3 --num_units=48 --n_jobs=2 --num_epochs=250 --batch_size=8 --do_train --do_evaluate --per_walk_models="/xxx/outbound/model.h5,/xxx/rest/model.h5,/xxx/return/model.h5"
Using TensorFlow backend.
INFO: Args are: {'create_submission_file': False, 'do_evaluate': True, 'attention_dropout': 0.2, 'fraction_of_data_set': 0.3, 'n_jobs': 2, 'signal': 'outbound', 'do_train': True, 'dropout': 0.4, 'batch_size': 8, 'output_directory': '/xxx/', 'test_dataset': '/xxx/dream-test', 'per_walk_models': '/xxx/model.h5,/xxx/model.h5,/xxx/model.h5', 'num_units': 48, 'missing_dataset': '/xxx/dream-missing', 'num_epochs': 250, 'validation_set_fraction': 0.3, 'dataset': '/xxx/', 'seed': 909, 'load_existing': '', 'submission_template': '/xxx/PDChallenge_SC1_SubmissionTemplate.csv', 'supplemental_dataset': '/xxx/dream-test'}
INFO: Built generators with 23521 training samples and 10080 validation samples. We are using 7056 / 23521 for training and 10080 / 10080 for validation.
INFO: Started training feature extraction.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, None, 13)      0
____________________________________________________________________________________________________
masking_1 (Masking)              (None, None, 13)      0           input_1[0][0]
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 1, None, 13)   0           masking_1[0][0]
____________________________________________________________________________________________________
conv2d_2 (Conv2D)                (None, 32, None, 13)  320         lambda_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 32, None, 13)  0           conv2d_2[0][0]
____________________________________________________________________________________________________
average_pooling2d_1 (AveragePool (None, 1, None, 13)   0           lambda_1[0][0]
____________________________________________________________________________________________________
conv2d_3 (Conv2D)                (None, 32, None, 13)  9248        activation_1[0][0]
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, 32, None, 13)  64          average_pooling2d_1[0][0]
____________________________________________________________________________________________________
average_pooling2d_2 (AveragePool (None, 32, None, 13)  0           conv2d_3[0][0]
____________________________________________________________________________________________________
add_1 (Add)                      (None, 32, None, 13)  0           conv2d_1[0][0]
                                                                   average_pooling2d_2[0][0]
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 32, None, 13)  128         add_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 32, None, 13)  0           batch_normalization_1[0][0]
____________________________________________________________________________________________________
conv2d_4 (Conv2D)                (None, 32, None, 13)  9248        activation_2[0][0]
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 32, None, 13)  128         conv2d_4[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 32, None, 13)  0           batch_normalization_2[0][0]
____________________________________________________________________________________________________
conv2d_6 (Conv2D)                (None, 32, None, 13)  1056        add_1[0][0]
____________________________________________________________________________________________________
conv2d_5 (Conv2D)                (None, 32, None, 13)  9248        activation_3[0][0]
____________________________________________________________________________________________________
average_pooling2d_4 (AveragePool (None, 32, None, 13)  0           conv2d_6[0][0]
____________________________________________________________________________________________________
average_pooling2d_3 (AveragePool (None, 32, None, 13)  0           conv2d_5[0][0]
____________________________________________________________________________________________________
add_2 (Add)                      (None, 32, None, 13)  0           average_pooling2d_4[0][0]
                                                                   average_pooling2d_3[0][0]
____________________________________________________________________________________________________
batch_normalization_3 (BatchNorm (None, 32, None, 13)  128         add_2[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 32, None, 13)  0           batch_normalization_3[0][0]
____________________________________________________________________________________________________
conv2d_7 (Conv2D)                (None, 32, None, 13)  9248        activation_4[0][0]
____________________________________________________________________________________________________
batch_normalization_4 (BatchNorm (None, 32, None, 13)  128         conv2d_7[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 32, None, 13)  0           batch_normalization_4[0][0]
____________________________________________________________________________________________________
conv2d_9 (Conv2D)                (None, 32, None, 13)  1056        add_2[0][0]
____________________________________________________________________________________________________
conv2d_8 (Conv2D)                (None, 32, None, 13)  9248        activation_5[0][0]
____________________________________________________________________________________________________
average_pooling2d_6 (AveragePool (None, 32, None, 13)  0           conv2d_9[0][0]
____________________________________________________________________________________________________
average_pooling2d_5 (AveragePool (None, 32, None, 13)  0           conv2d_8[0][0]
____________________________________________________________________________________________________
add_3 (Add)                      (None, 32, None, 13)  0           average_pooling2d_6[0][0]
                                                                   average_pooling2d_5[0][0]
____________________________________________________________________________________________________
batch_normalization_5 (BatchNorm (None, 32, None, 13)  128         add_3[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 32, None, 13)  0           batch_normalization_5[0][0]
____________________________________________________________________________________________________
conv2d_10 (Conv2D)               (None, 32, None, 13)  9248        activation_6[0][0]
____________________________________________________________________________________________________
batch_normalization_6 (BatchNorm (None, 32, None, 13)  128         conv2d_10[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 32, None, 13)  0           batch_normalization_6[0][0]
____________________________________________________________________________________________________
conv2d_12 (Conv2D)               (None, 32, None, 13)  1056        add_3[0][0]
____________________________________________________________________________________________________
conv2d_11 (Conv2D)               (None, 32, None, 13)  9248        activation_7[0][0]
____________________________________________________________________________________________________
average_pooling2d_8 (AveragePool (None, 32, None, 13)  0           conv2d_12[0][0]
____________________________________________________________________________________________________
average_pooling2d_7 (AveragePool (None, 32, None, 13)  0           conv2d_11[0][0]
____________________________________________________________________________________________________
add_4 (Add)                      (None, 32, None, 13)  0           average_pooling2d_8[0][0]
                                                                   average_pooling2d_7[0][0]
____________________________________________________________________________________________________
batch_normalization_7 (BatchNorm (None, 32, None, 13)  128         add_4[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 32, None, 13)  0           batch_normalization_7[0][0]
____________________________________________________________________________________________________
conv2d_13 (Conv2D)               (None, 32, None, 13)  9248        activation_8[0][0]
____________________________________________________________________________________________________
batch_normalization_8 (BatchNorm (None, 32, None, 13)  128         conv2d_13[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 32, None, 13)  0           batch_normalization_8[0][0]
____________________________________________________________________________________________________
conv2d_15 (Conv2D)               (None, 32, None, 13)  1056        add_4[0][0]
____________________________________________________________________________________________________
conv2d_14 (Conv2D)               (None, 32, None, 13)  9248        activation_9[0][0]
____________________________________________________________________________________________________
average_pooling2d_10 (AveragePoo (None, 32, None, 13)  0           conv2d_15[0][0]
____________________________________________________________________________________________________
average_pooling2d_9 (AveragePool (None, 32, None, 13)  0           conv2d_14[0][0]
____________________________________________________________________________________________________
add_5 (Add)                      (None, 32, None, 13)  0           average_pooling2d_10[0][0]
                                                                   average_pooling2d_9[0][0]
____________________________________________________________________________________________________
batch_normalization_9 (BatchNorm (None, 32, None, 13)  128         add_5[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 32, None, 13)  0           batch_normalization_9[0][0]
____________________________________________________________________________________________________
conv2d_16 (Conv2D)               (None, 32, None, 13)  9248        activation_10[0][0]
____________________________________________________________________________________________________
batch_normalization_10 (BatchNor (None, 32, None, 13)  128         conv2d_16[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 32, None, 13)  0           batch_normalization_10[0][0]
____________________________________________________________________________________________________
conv2d_18 (Conv2D)               (None, 32, None, 13)  1056        add_5[0][0]
____________________________________________________________________________________________________
conv2d_17 (Conv2D)               (None, 32, None, 13)  9248        activation_11[0][0]
____________________________________________________________________________________________________
average_pooling2d_12 (AveragePoo (None, 32, None, 13)  0           conv2d_18[0][0]
____________________________________________________________________________________________________
average_pooling2d_11 (AveragePoo (None, 32, None, 13)  0           conv2d_17[0][0]
____________________________________________________________________________________________________
add_6 (Add)                      (None, 32, None, 13)  0           average_pooling2d_12[0][0]
                                                                   average_pooling2d_11[0][0]
____________________________________________________________________________________________________
batch_normalization_11 (BatchNor (None, 32, None, 13)  128         add_6[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 32, None, 13)  0           batch_normalization_11[0][0]
____________________________________________________________________________________________________
conv2d_19 (Conv2D)               (None, 1, None, 13)   289         activation_12[0][0]
____________________________________________________________________________________________________
lambda_2 (Lambda)                (None, None, 13)      0           conv2d_19[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, None, 64)      11776       lambda_2[0][0]
____________________________________________________________________________________________________
soft_attention_1 (SoftAttention) (None, 64)            4224        bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 32)            2080        soft_attention_1[0][0]
____________________________________________________________________________________________________
batch_normalization_12 (BatchNor (None, 32)            128         dense_1[0][0]
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 32)            0           batch_normalization_12[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32)            0           activation_13[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 32)            1056        dropout_1[0][0]
____________________________________________________________________________________________________
batch_normalization_13 (BatchNor (None, 32)            128         dense_2[0][0]
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 32)            0           batch_normalization_13[0][0]
____________________________________________________________________________________________________
input_2 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
input_3 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32)            0           activation_14[0][0]
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 34)            0           input_2[0][0]
                                                                   input_3[0][0]
                                                                   dropout_2[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_1[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
2017-10-02 23:13:19.026704: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-02 23:13:19.026721: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-02 23:13:19.026725: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-02 23:13:19.026728: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed upCPU computations.
2017-10-02 23:13:19.026731: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-10-02 23:13:19.762741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 970
major: 5 minor: 2 memoryClockRate (GHz) 1.253
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.88GiB
2017-10-02 23:13:19.762765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-10-02 23:13:19.762770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-10-02 23:13:19.762775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_4 (InputLayer)             (None, None, 13)      0
____________________________________________________________________________________________________
masking_2 (Masking)              (None, None, 13)      0           input_4[0][0]
____________________________________________________________________________________________________
lambda_3 (Lambda)                (None, 1, None, 13)   0           masking_2[0][0]
____________________________________________________________________________________________________
conv2d_21 (Conv2D)               (None, 32, None, 13)  320         lambda_3[0][0]
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 32, None, 13)  0           conv2d_21[0][0]
____________________________________________________________________________________________________
average_pooling2d_13 (AveragePoo (None, 1, None, 13)   0           lambda_3[0][0]
____________________________________________________________________________________________________
conv2d_22 (Conv2D)               (None, 32, None, 13)  9248        activation_15[0][0]
____________________________________________________________________________________________________
conv2d_20 (Conv2D)               (None, 32, None, 13)  64          average_pooling2d_13[0][0]
____________________________________________________________________________________________________
average_pooling2d_14 (AveragePoo (None, 32, None, 13)  0           conv2d_22[0][0]
____________________________________________________________________________________________________
add_7 (Add)                      (None, 32, None, 13)  0           conv2d_20[0][0]
                                                                   average_pooling2d_14[0][0]
____________________________________________________________________________________________________
batch_normalization_14 (BatchNor (None, 32, None, 13)  128         add_7[0][0]
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 32, None, 13)  0           batch_normalization_14[0][0]
____________________________________________________________________________________________________
conv2d_23 (Conv2D)               (None, 32, None, 13)  9248        activation_16[0][0]
____________________________________________________________________________________________________
batch_normalization_15 (BatchNor (None, 32, None, 13)  128         conv2d_23[0][0]
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 32, None, 13)  0           batch_normalization_15[0][0]
____________________________________________________________________________________________________
conv2d_25 (Conv2D)               (None, 32, None, 13)  1056        add_7[0][0]
____________________________________________________________________________________________________
conv2d_24 (Conv2D)               (None, 32, None, 13)  9248        activation_17[0][0]
____________________________________________________________________________________________________
average_pooling2d_16 (AveragePoo (None, 32, None, 13)  0           conv2d_25[0][0]
____________________________________________________________________________________________________
average_pooling2d_15 (AveragePoo (None, 32, None, 13)  0           conv2d_24[0][0]
____________________________________________________________________________________________________
add_8 (Add)                      (None, 32, None, 13)  0           average_pooling2d_16[0][0]
                                                                   average_pooling2d_15[0][0]
____________________________________________________________________________________________________
batch_normalization_16 (BatchNor (None, 32, None, 13)  128         add_8[0][0]
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 32, None, 13)  0           batch_normalization_16[0][0]
____________________________________________________________________________________________________
conv2d_26 (Conv2D)               (None, 32, None, 13)  9248        activation_18[0][0]
____________________________________________________________________________________________________
batch_normalization_17 (BatchNor (None, 32, None, 13)  128         conv2d_26[0][0]
____________________________________________________________________________________________________
activation_19 (Activation)       (None, 32, None, 13)  0           batch_normalization_17[0][0]
____________________________________________________________________________________________________
conv2d_28 (Conv2D)               (None, 32, None, 13)  1056        add_8[0][0]
____________________________________________________________________________________________________
conv2d_27 (Conv2D)               (None, 32, None, 13)  9248        activation_19[0][0]
____________________________________________________________________________________________________
average_pooling2d_18 (AveragePoo (None, 32, None, 13)  0           conv2d_28[0][0]
____________________________________________________________________________________________________
average_pooling2d_17 (AveragePoo (None, 32, None, 13)  0           conv2d_27[0][0]
____________________________________________________________________________________________________
add_9 (Add)                      (None, 32, None, 13)  0           average_pooling2d_18[0][0]
                                                                   average_pooling2d_17[0][0]
____________________________________________________________________________________________________
batch_normalization_18 (BatchNor (None, 32, None, 13)  128         add_9[0][0]
____________________________________________________________________________________________________
activation_20 (Activation)       (None, 32, None, 13)  0           batch_normalization_18[0][0]
____________________________________________________________________________________________________
conv2d_29 (Conv2D)               (None, 32, None, 13)  9248        activation_20[0][0]
____________________________________________________________________________________________________
batch_normalization_19 (BatchNor (None, 32, None, 13)  128         conv2d_29[0][0]
____________________________________________________________________________________________________
activation_21 (Activation)       (None, 32, None, 13)  0           batch_normalization_19[0][0]
____________________________________________________________________________________________________
conv2d_31 (Conv2D)               (None, 32, None, 13)  1056        add_9[0][0]
____________________________________________________________________________________________________
conv2d_30 (Conv2D)               (None, 32, None, 13)  9248        activation_21[0][0]
____________________________________________________________________________________________________
average_pooling2d_20 (AveragePoo (None, 32, None, 13)  0           conv2d_31[0][0]
____________________________________________________________________________________________________
average_pooling2d_19 (AveragePoo (None, 32, None, 13)  0           conv2d_30[0][0]
____________________________________________________________________________________________________
add_10 (Add)                     (None, 32, None, 13)  0           average_pooling2d_20[0][0]
                                                                   average_pooling2d_19[0][0]
____________________________________________________________________________________________________
batch_normalization_20 (BatchNor (None, 32, None, 13)  128         add_10[0][0]
____________________________________________________________________________________________________
activation_22 (Activation)       (None, 32, None, 13)  0           batch_normalization_20[0][0]
____________________________________________________________________________________________________
conv2d_32 (Conv2D)               (None, 32, None, 13)  9248        activation_22[0][0]
____________________________________________________________________________________________________
batch_normalization_21 (BatchNor (None, 32, None, 13)  128         conv2d_32[0][0]
____________________________________________________________________________________________________
activation_23 (Activation)       (None, 32, None, 13)  0           batch_normalization_21[0][0]
____________________________________________________________________________________________________
conv2d_34 (Conv2D)               (None, 32, None, 13)  1056        add_10[0][0]
____________________________________________________________________________________________________
conv2d_33 (Conv2D)               (None, 32, None, 13)  9248        activation_23[0][0]
____________________________________________________________________________________________________
average_pooling2d_22 (AveragePoo (None, 32, None, 13)  0           conv2d_34[0][0]
____________________________________________________________________________________________________
average_pooling2d_21 (AveragePoo (None, 32, None, 13)  0           conv2d_33[0][0]
____________________________________________________________________________________________________
add_11 (Add)                     (None, 32, None, 13)  0           average_pooling2d_22[0][0]
                                                                   average_pooling2d_21[0][0]
____________________________________________________________________________________________________
batch_normalization_22 (BatchNor (None, 32, None, 13)  128         add_11[0][0]
____________________________________________________________________________________________________
activation_24 (Activation)       (None, 32, None, 13)  0           batch_normalization_22[0][0]
____________________________________________________________________________________________________
conv2d_35 (Conv2D)               (None, 32, None, 13)  9248        activation_24[0][0]
____________________________________________________________________________________________________
batch_normalization_23 (BatchNor (None, 32, None, 13)  128         conv2d_35[0][0]
____________________________________________________________________________________________________
activation_25 (Activation)       (None, 32, None, 13)  0           batch_normalization_23[0][0]
____________________________________________________________________________________________________
conv2d_37 (Conv2D)               (None, 32, None, 13)  1056        add_11[0][0]
____________________________________________________________________________________________________
conv2d_36 (Conv2D)               (None, 32, None, 13)  9248        activation_25[0][0]
____________________________________________________________________________________________________
average_pooling2d_24 (AveragePoo (None, 32, None, 13)  0           conv2d_37[0][0]
____________________________________________________________________________________________________
average_pooling2d_23 (AveragePoo (None, 32, None, 13)  0           conv2d_36[0][0]
____________________________________________________________________________________________________
add_12 (Add)                     (None, 32, None, 13)  0           average_pooling2d_24[0][0]
                                                                   average_pooling2d_23[0][0]
____________________________________________________________________________________________________
batch_normalization_24 (BatchNor (None, 32, None, 13)  128         add_12[0][0]
____________________________________________________________________________________________________
activation_26 (Activation)       (None, 32, None, 13)  0           batch_normalization_24[0][0]
____________________________________________________________________________________________________
conv2d_38 (Conv2D)               (None, 1, None, 13)   289         activation_26[0][0]
____________________________________________________________________________________________________
lambda_4 (Lambda)                (None, None, 13)      0           conv2d_38[0][0]
____________________________________________________________________________________________________
bidirectional_2 (Bidirectional)  (None, None, 64)      11776       lambda_4[0][0]
____________________________________________________________________________________________________
soft_attention_2 (SoftAttention) (None, 64)            4224        bidirectional_2[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 32)            2080        soft_attention_2[0][0]
____________________________________________________________________________________________________
batch_normalization_25 (BatchNor (None, 32)            128         dense_3[0][0]
____________________________________________________________________________________________________
activation_27 (Activation)       (None, 32)            0           batch_normalization_25[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 32)            0           activation_27[0][0]
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 32)            1056        dropout_3[0][0]
____________________________________________________________________________________________________
batch_normalization_26 (BatchNor (None, 32)            128         dense_4[0][0]
____________________________________________________________________________________________________
activation_28 (Activation)       (None, 32)            0           batch_normalization_26[0][0]
____________________________________________________________________________________________________
input_5 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
input_6 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 32)            0           activation_28[0][0]
____________________________________________________________________________________________________
concatenate_2 (Concatenate)      (None, 34)            0           input_5[0][0]
                                                                   input_6[0][0]
                                                                   dropout_4[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_2[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_7 (InputLayer)             (None, None, 13)      0
____________________________________________________________________________________________________
masking_3 (Masking)              (None, None, 13)      0           input_7[0][0]
____________________________________________________________________________________________________
lambda_5 (Lambda)                (None, 1, None, 13)   0           masking_3[0][0]
____________________________________________________________________________________________________
conv2d_40 (Conv2D)               (None, 32, None, 13)  320         lambda_5[0][0]
____________________________________________________________________________________________________
activation_29 (Activation)       (None, 32, None, 13)  0           conv2d_40[0][0]
____________________________________________________________________________________________________
average_pooling2d_25 (AveragePoo (None, 1, None, 13)   0           lambda_5[0][0]
____________________________________________________________________________________________________
conv2d_41 (Conv2D)               (None, 32, None, 13)  9248        activation_29[0][0]
____________________________________________________________________________________________________
conv2d_39 (Conv2D)               (None, 32, None, 13)  64          average_pooling2d_25[0][0]
____________________________________________________________________________________________________
average_pooling2d_26 (AveragePoo (None, 32, None, 13)  0           conv2d_41[0][0]
____________________________________________________________________________________________________
add_13 (Add)                     (None, 32, None, 13)  0           conv2d_39[0][0]
                                                                   average_pooling2d_26[0][0]
____________________________________________________________________________________________________
batch_normalization_27 (BatchNor (None, 32, None, 13)  128         add_13[0][0]
____________________________________________________________________________________________________
activation_30 (Activation)       (None, 32, None, 13)  0           batch_normalization_27[0][0]
____________________________________________________________________________________________________
conv2d_42 (Conv2D)               (None, 32, None, 13)  9248        activation_30[0][0]
____________________________________________________________________________________________________
batch_normalization_28 (BatchNor (None, 32, None, 13)  128         conv2d_42[0][0]
____________________________________________________________________________________________________
activation_31 (Activation)       (None, 32, None, 13)  0           batch_normalization_28[0][0]
____________________________________________________________________________________________________
conv2d_44 (Conv2D)               (None, 32, None, 13)  1056        add_13[0][0]
____________________________________________________________________________________________________
conv2d_43 (Conv2D)               (None, 32, None, 13)  9248        activation_31[0][0]
____________________________________________________________________________________________________
average_pooling2d_28 (AveragePoo (None, 32, None, 13)  0           conv2d_44[0][0]
____________________________________________________________________________________________________
average_pooling2d_27 (AveragePoo (None, 32, None, 13)  0           conv2d_43[0][0]
____________________________________________________________________________________________________
add_14 (Add)                     (None, 32, None, 13)  0           average_pooling2d_28[0][0]
                                                                   average_pooling2d_27[0][0]
____________________________________________________________________________________________________
batch_normalization_29 (BatchNor (None, 32, None, 13)  128         add_14[0][0]
____________________________________________________________________________________________________
activation_32 (Activation)       (None, 32, None, 13)  0           batch_normalization_29[0][0]
____________________________________________________________________________________________________
conv2d_45 (Conv2D)               (None, 32, None, 13)  9248        activation_32[0][0]
____________________________________________________________________________________________________
batch_normalization_30 (BatchNor (None, 32, None, 13)  128         conv2d_45[0][0]
____________________________________________________________________________________________________
activation_33 (Activation)       (None, 32, None, 13)  0           batch_normalization_30[0][0]
____________________________________________________________________________________________________
conv2d_47 (Conv2D)               (None, 32, None, 13)  1056        add_14[0][0]
____________________________________________________________________________________________________
conv2d_46 (Conv2D)               (None, 32, None, 13)  9248        activation_33[0][0]
____________________________________________________________________________________________________
average_pooling2d_30 (AveragePoo (None, 32, None, 13)  0           conv2d_47[0][0]
____________________________________________________________________________________________________
average_pooling2d_29 (AveragePoo (None, 32, None, 13)  0           conv2d_46[0][0]
____________________________________________________________________________________________________
add_15 (Add)                     (None, 32, None, 13)  0           average_pooling2d_30[0][0]
                                                                   average_pooling2d_29[0][0]
____________________________________________________________________________________________________
batch_normalization_31 (BatchNor (None, 32, None, 13)  128         add_15[0][0]
____________________________________________________________________________________________________
activation_34 (Activation)       (None, 32, None, 13)  0           batch_normalization_31[0][0]
____________________________________________________________________________________________________
conv2d_48 (Conv2D)               (None, 32, None, 13)  9248        activation_34[0][0]
____________________________________________________________________________________________________
batch_normalization_32 (BatchNor (None, 32, None, 13)  128         conv2d_48[0][0]
____________________________________________________________________________________________________
activation_35 (Activation)       (None, 32, None, 13)  0           batch_normalization_32[0][0]
____________________________________________________________________________________________________
conv2d_50 (Conv2D)               (None, 32, None, 13)  1056        add_15[0][0]
____________________________________________________________________________________________________
conv2d_49 (Conv2D)               (None, 32, None, 13)  9248        activation_35[0][0]
____________________________________________________________________________________________________
average_pooling2d_32 (AveragePoo (None, 32, None, 13)  0           conv2d_50[0][0]
____________________________________________________________________________________________________
average_pooling2d_31 (AveragePoo (None, 32, None, 13)  0           conv2d_49[0][0]
____________________________________________________________________________________________________
add_16 (Add)                     (None, 32, None, 13)  0           average_pooling2d_32[0][0]
                                                                   average_pooling2d_31[0][0]
____________________________________________________________________________________________________
batch_normalization_33 (BatchNor (None, 32, None, 13)  128         add_16[0][0]
____________________________________________________________________________________________________
activation_36 (Activation)       (None, 32, None, 13)  0           batch_normalization_33[0][0]
____________________________________________________________________________________________________
conv2d_51 (Conv2D)               (None, 32, None, 13)  9248        activation_36[0][0]
____________________________________________________________________________________________________
batch_normalization_34 (BatchNor (None, 32, None, 13)  128         conv2d_51[0][0]
____________________________________________________________________________________________________
activation_37 (Activation)       (None, 32, None, 13)  0           batch_normalization_34[0][0]
____________________________________________________________________________________________________
conv2d_53 (Conv2D)               (None, 32, None, 13)  1056        add_16[0][0]
____________________________________________________________________________________________________
conv2d_52 (Conv2D)               (None, 32, None, 13)  9248        activation_37[0][0]
____________________________________________________________________________________________________
average_pooling2d_34 (AveragePoo (None, 32, None, 13)  0           conv2d_53[0][0]
____________________________________________________________________________________________________
average_pooling2d_33 (AveragePoo (None, 32, None, 13)  0           conv2d_52[0][0]
____________________________________________________________________________________________________
add_17 (Add)                     (None, 32, None, 13)  0           average_pooling2d_34[0][0]
                                                                   average_pooling2d_33[0][0]
____________________________________________________________________________________________________
batch_normalization_35 (BatchNor (None, 32, None, 13)  128         add_17[0][0]
____________________________________________________________________________________________________
activation_38 (Activation)       (None, 32, None, 13)  0           batch_normalization_35[0][0]
____________________________________________________________________________________________________
conv2d_54 (Conv2D)               (None, 32, None, 13)  9248        activation_38[0][0]
____________________________________________________________________________________________________
batch_normalization_36 (BatchNor (None, 32, None, 13)  128         conv2d_54[0][0]
____________________________________________________________________________________________________
activation_39 (Activation)       (None, 32, None, 13)  0           batch_normalization_36[0][0]
____________________________________________________________________________________________________
conv2d_56 (Conv2D)               (None, 32, None, 13)  1056        add_17[0][0]
____________________________________________________________________________________________________
conv2d_55 (Conv2D)               (None, 32, None, 13)  9248        activation_39[0][0]
____________________________________________________________________________________________________
average_pooling2d_36 (AveragePoo (None, 32, None, 13)  0           conv2d_56[0][0]
____________________________________________________________________________________________________
average_pooling2d_35 (AveragePoo (None, 32, None, 13)  0           conv2d_55[0][0]
____________________________________________________________________________________________________
add_18 (Add)                     (None, 32, None, 13)  0           average_pooling2d_36[0][0]
                                                                   average_pooling2d_35[0][0]
____________________________________________________________________________________________________
batch_normalization_37 (BatchNor (None, 32, None, 13)  128         add_18[0][0]
____________________________________________________________________________________________________
activation_40 (Activation)       (None, 32, None, 13)  0           batch_normalization_37[0][0]
____________________________________________________________________________________________________
conv2d_57 (Conv2D)               (None, 1, None, 13)   289         activation_40[0][0]
____________________________________________________________________________________________________
lambda_6 (Lambda)                (None, None, 13)      0           conv2d_57[0][0]
____________________________________________________________________________________________________
bidirectional_3 (Bidirectional)  (None, None, 64)      11776       lambda_6[0][0]
____________________________________________________________________________________________________
soft_attention_3 (SoftAttention) (None, 64)            4224        bidirectional_3[0][0]
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 32)            2080        soft_attention_3[0][0]
____________________________________________________________________________________________________
batch_normalization_38 (BatchNor (None, 32)            128         dense_5[0][0]
____________________________________________________________________________________________________
activation_41 (Activation)       (None, 32)            0           batch_normalization_38[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 32)            0           activation_41[0][0]
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 32)            1056        dropout_5[0][0]
____________________________________________________________________________________________________
batch_normalization_39 (BatchNor (None, 32)            128         dense_6[0][0]
____________________________________________________________________________________________________
activation_42 (Activation)       (None, 32)            0           batch_normalization_39[0][0]
____________________________________________________________________________________________________
input_8 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
input_9 (InputLayer)             (None, 1)             0
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 32)            0           activation_42[0][0]
____________________________________________________________________________________________________
concatenate_3 (Concatenate)      (None, 34)            0           input_8[0][0]
                                                                   input_9[0][0]
                                                                   dropout_6[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_3[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_10 (InputLayer)            (None, None, 13)      0
____________________________________________________________________________________________________
masking_4 (Masking)              (None, None, 13)      0           input_10[0][0]
____________________________________________________________________________________________________
lambda_7 (Lambda)                (None, 1, None, 13)   0           masking_4[0][0]
____________________________________________________________________________________________________
conv2d_59 (Conv2D)               (None, 32, None, 13)  320         lambda_7[0][0]
____________________________________________________________________________________________________
activation_43 (Activation)       (None, 32, None, 13)  0           conv2d_59[0][0]
____________________________________________________________________________________________________
average_pooling2d_37 (AveragePoo (None, 1, None, 13)   0           lambda_7[0][0]
____________________________________________________________________________________________________
conv2d_60 (Conv2D)               (None, 32, None, 13)  9248        activation_43[0][0]
____________________________________________________________________________________________________
conv2d_58 (Conv2D)               (None, 32, None, 13)  64          average_pooling2d_37[0][0]
____________________________________________________________________________________________________
average_pooling2d_38 (AveragePoo (None, 32, None, 13)  0           conv2d_60[0][0]
____________________________________________________________________________________________________
add_19 (Add)                     (None, 32, None, 13)  0           conv2d_58[0][0]
                                                                   average_pooling2d_38[0][0]
____________________________________________________________________________________________________
batch_normalization_40 (BatchNor (None, 32, None, 13)  128         add_19[0][0]
____________________________________________________________________________________________________
activation_44 (Activation)       (None, 32, None, 13)  0           batch_normalization_40[0][0]
____________________________________________________________________________________________________
conv2d_61 (Conv2D)               (None, 32, None, 13)  9248        activation_44[0][0]
____________________________________________________________________________________________________
batch_normalization_41 (BatchNor (None, 32, None, 13)  128         conv2d_61[0][0]
____________________________________________________________________________________________________
activation_45 (Activation)       (None, 32, None, 13)  0           batch_normalization_41[0][0]
____________________________________________________________________________________________________
conv2d_63 (Conv2D)               (None, 32, None, 13)  1056        add_19[0][0]
____________________________________________________________________________________________________
conv2d_62 (Conv2D)               (None, 32, None, 13)  9248        activation_45[0][0]
____________________________________________________________________________________________________
average_pooling2d_40 (AveragePoo (None, 32, None, 13)  0           conv2d_63[0][0]
____________________________________________________________________________________________________
average_pooling2d_39 (AveragePoo (None, 32, None, 13)  0           conv2d_62[0][0]
____________________________________________________________________________________________________
add_20 (Add)                     (None, 32, None, 13)  0           average_pooling2d_40[0][0]
                                                                   average_pooling2d_39[0][0]
____________________________________________________________________________________________________
batch_normalization_42 (BatchNor (None, 32, None, 13)  128         add_20[0][0]
____________________________________________________________________________________________________
activation_46 (Activation)       (None, 32, None, 13)  0           batch_normalization_42[0][0]
____________________________________________________________________________________________________
conv2d_64 (Conv2D)               (None, 32, None, 13)  9248        activation_46[0][0]
____________________________________________________________________________________________________
batch_normalization_43 (BatchNor (None, 32, None, 13)  128         conv2d_64[0][0]
____________________________________________________________________________________________________
activation_47 (Activation)       (None, 32, None, 13)  0           batch_normalization_43[0][0]
____________________________________________________________________________________________________
conv2d_66 (Conv2D)               (None, 32, None, 13)  1056        add_20[0][0]
____________________________________________________________________________________________________
conv2d_65 (Conv2D)               (None, 32, None, 13)  9248        activation_47[0][0]
____________________________________________________________________________________________________
average_pooling2d_42 (AveragePoo (None, 32, None, 13)  0           conv2d_66[0][0]
____________________________________________________________________________________________________
average_pooling2d_41 (AveragePoo (None, 32, None, 13)  0           conv2d_65[0][0]
____________________________________________________________________________________________________
add_21 (Add)                     (None, 32, None, 13)  0           average_pooling2d_42[0][0]
                                                                   average_pooling2d_41[0][0]
____________________________________________________________________________________________________
batch_normalization_44 (BatchNor (None, 32, None, 13)  128         add_21[0][0]
____________________________________________________________________________________________________
activation_48 (Activation)       (None, 32, None, 13)  0           batch_normalization_44[0][0]
____________________________________________________________________________________________________
conv2d_67 (Conv2D)               (None, 32, None, 13)  9248        activation_48[0][0]
____________________________________________________________________________________________________
batch_normalization_45 (BatchNor (None, 32, None, 13)  128         conv2d_67[0][0]
____________________________________________________________________________________________________
activation_49 (Activation)       (None, 32, None, 13)  0           batch_normalization_45[0][0]
____________________________________________________________________________________________________
conv2d_69 (Conv2D)               (None, 32, None, 13)  1056        add_21[0][0]
____________________________________________________________________________________________________
conv2d_68 (Conv2D)               (None, 32, None, 13)  9248        activation_49[0][0]
____________________________________________________________________________________________________
average_pooling2d_44 (AveragePoo (None, 32, None, 13)  0           conv2d_69[0][0]
____________________________________________________________________________________________________
average_pooling2d_43 (AveragePoo (None, 32, None, 13)  0           conv2d_68[0][0]
____________________________________________________________________________________________________
add_22 (Add)                     (None, 32, None, 13)  0           average_pooling2d_44[0][0]
                                                                   average_pooling2d_43[0][0]
____________________________________________________________________________________________________
batch_normalization_46 (BatchNor (None, 32, None, 13)  128         add_22[0][0]
____________________________________________________________________________________________________
activation_50 (Activation)       (None, 32, None, 13)  0           batch_normalization_46[0][0]
____________________________________________________________________________________________________
conv2d_70 (Conv2D)               (None, 32, None, 13)  9248        activation_50[0][0]
____________________________________________________________________________________________________
batch_normalization_47 (BatchNor (None, 32, None, 13)  128         conv2d_70[0][0]
____________________________________________________________________________________________________
activation_51 (Activation)       (None, 32, None, 13)  0           batch_normalization_47[0][0]
____________________________________________________________________________________________________
conv2d_72 (Conv2D)               (None, 32, None, 13)  1056        add_22[0][0]
____________________________________________________________________________________________________
conv2d_71 (Conv2D)               (None, 32, None, 13)  9248        activation_51[0][0]
____________________________________________________________________________________________________
average_pooling2d_46 (AveragePoo (None, 32, None, 13)  0           conv2d_72[0][0]
____________________________________________________________________________________________________
average_pooling2d_45 (AveragePoo (None, 32, None, 13)  0           conv2d_71[0][0]
____________________________________________________________________________________________________
add_23 (Add)                     (None, 32, None, 13)  0           average_pooling2d_46[0][0]
                                                                   average_pooling2d_45[0][0]
____________________________________________________________________________________________________
batch_normalization_48 (BatchNor (None, 32, None, 13)  128         add_23[0][0]
____________________________________________________________________________________________________
activation_52 (Activation)       (None, 32, None, 13)  0           batch_normalization_48[0][0]
____________________________________________________________________________________________________
conv2d_73 (Conv2D)               (None, 32, None, 13)  9248        activation_52[0][0]
____________________________________________________________________________________________________
batch_normalization_49 (BatchNor (None, 32, None, 13)  128         conv2d_73[0][0]
____________________________________________________________________________________________________
activation_53 (Activation)       (None, 32, None, 13)  0           batch_normalization_49[0][0]
____________________________________________________________________________________________________
conv2d_75 (Conv2D)               (None, 32, None, 13)  1056        add_23[0][0]
____________________________________________________________________________________________________
conv2d_74 (Conv2D)               (None, 32, None, 13)  9248        activation_53[0][0]
____________________________________________________________________________________________________
average_pooling2d_48 (AveragePoo (None, 32, None, 13)  0           conv2d_75[0][0]
____________________________________________________________________________________________________
average_pooling2d_47 (AveragePoo (None, 32, None, 13)  0           conv2d_74[0][0]
____________________________________________________________________________________________________
add_24 (Add)                     (None, 32, None, 13)  0           average_pooling2d_48[0][0]
                                                                   average_pooling2d_47[0][0]
____________________________________________________________________________________________________
batch_normalization_50 (BatchNor (None, 32, None, 13)  128         add_24[0][0]
____________________________________________________________________________________________________
activation_54 (Activation)       (None, 32, None, 13)  0           batch_normalization_50[0][0]
____________________________________________________________________________________________________
conv2d_76 (Conv2D)               (None, 1, None, 13)   289         activation_54[0][0]
____________________________________________________________________________________________________
lambda_8 (Lambda)                (None, None, 13)      0           conv2d_76[0][0]
____________________________________________________________________________________________________
bidirectional_4 (Bidirectional)  (None, None, 64)      11776       lambda_8[0][0]
____________________________________________________________________________________________________
soft_attention_4 (SoftAttention) (None, 64)            4224        bidirectional_4[0][0]
____________________________________________________________________________________________________
dense_7 (Dense)                  (None, 32)            2080        soft_attention_4[0][0]
____________________________________________________________________________________________________
batch_normalization_51 (BatchNor (None, 32)            128         dense_7[0][0]
____________________________________________________________________________________________________
activation_55 (Activation)       (None, 32)            0           batch_normalization_51[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 32)            0           activation_55[0][0]
____________________________________________________________________________________________________
dense_8 (Dense)                  (None, 32)            1056        dropout_7[0][0]
____________________________________________________________________________________________________
batch_normalization_52 (BatchNor (None, 32)            128         dense_8[0][0]
____________________________________________________________________________________________________
activation_56 (Activation)       (None, 32)            0           batch_normalization_52[0][0]
____________________________________________________________________________________________________
input_11 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_12 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 32)            0           activation_56[0][0]
____________________________________________________________________________________________________
concatenate_4 (Concatenate)      (None, 34)            0           input_11[0][0]
                                                                   input_12[0][0]
                                                                   dropout_8[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_4[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_13 (InputLayer)            (None, None, 13)      0
____________________________________________________________________________________________________
masking_5 (Masking)              (None, None, 13)      0           input_13[0][0]
____________________________________________________________________________________________________
lambda_9 (Lambda)                (None, 1, None, 13)   0           masking_5[0][0]
____________________________________________________________________________________________________
conv2d_78 (Conv2D)               (None, 32, None, 13)  320         lambda_9[0][0]
____________________________________________________________________________________________________
activation_57 (Activation)       (None, 32, None, 13)  0           conv2d_78[0][0]
____________________________________________________________________________________________________
average_pooling2d_49 (AveragePoo (None, 1, None, 13)   0           lambda_9[0][0]
____________________________________________________________________________________________________
conv2d_79 (Conv2D)               (None, 32, None, 13)  9248        activation_57[0][0]
____________________________________________________________________________________________________
conv2d_77 (Conv2D)               (None, 32, None, 13)  64          average_pooling2d_49[0][0]
____________________________________________________________________________________________________
average_pooling2d_50 (AveragePoo (None, 32, None, 13)  0           conv2d_79[0][0]
____________________________________________________________________________________________________
add_25 (Add)                     (None, 32, None, 13)  0           conv2d_77[0][0]
                                                                   average_pooling2d_50[0][0]
____________________________________________________________________________________________________
batch_normalization_53 (BatchNor (None, 32, None, 13)  128         add_25[0][0]
____________________________________________________________________________________________________
activation_58 (Activation)       (None, 32, None, 13)  0           batch_normalization_53[0][0]
____________________________________________________________________________________________________
conv2d_80 (Conv2D)               (None, 32, None, 13)  9248        activation_58[0][0]
____________________________________________________________________________________________________
batch_normalization_54 (BatchNor (None, 32, None, 13)  128         conv2d_80[0][0]
____________________________________________________________________________________________________
activation_59 (Activation)       (None, 32, None, 13)  0           batch_normalization_54[0][0]
____________________________________________________________________________________________________
conv2d_82 (Conv2D)               (None, 32, None, 13)  1056        add_25[0][0]
____________________________________________________________________________________________________
conv2d_81 (Conv2D)               (None, 32, None, 13)  9248        activation_59[0][0]
____________________________________________________________________________________________________
average_pooling2d_52 (AveragePoo (None, 32, None, 13)  0           conv2d_82[0][0]
____________________________________________________________________________________________________
average_pooling2d_51 (AveragePoo (None, 32, None, 13)  0           conv2d_81[0][0]
____________________________________________________________________________________________________
add_26 (Add)                     (None, 32, None, 13)  0           average_pooling2d_52[0][0]
                                                                   average_pooling2d_51[0][0]
____________________________________________________________________________________________________
batch_normalization_55 (BatchNor (None, 32, None, 13)  128         add_26[0][0]
____________________________________________________________________________________________________
activation_60 (Activation)       (None, 32, None, 13)  0           batch_normalization_55[0][0]
____________________________________________________________________________________________________
conv2d_83 (Conv2D)               (None, 32, None, 13)  9248        activation_60[0][0]
____________________________________________________________________________________________________
batch_normalization_56 (BatchNor (None, 32, None, 13)  128         conv2d_83[0][0]
____________________________________________________________________________________________________
activation_61 (Activation)       (None, 32, None, 13)  0           batch_normalization_56[0][0]
____________________________________________________________________________________________________
conv2d_85 (Conv2D)               (None, 32, None, 13)  1056        add_26[0][0]
____________________________________________________________________________________________________
conv2d_84 (Conv2D)               (None, 32, None, 13)  9248        activation_61[0][0]
____________________________________________________________________________________________________
average_pooling2d_54 (AveragePoo (None, 32, None, 13)  0           conv2d_85[0][0]
____________________________________________________________________________________________________
average_pooling2d_53 (AveragePoo (None, 32, None, 13)  0           conv2d_84[0][0]
____________________________________________________________________________________________________
add_27 (Add)                     (None, 32, None, 13)  0           average_pooling2d_54[0][0]
                                                                   average_pooling2d_53[0][0]
____________________________________________________________________________________________________
batch_normalization_57 (BatchNor (None, 32, None, 13)  128         add_27[0][0]
____________________________________________________________________________________________________
activation_62 (Activation)       (None, 32, None, 13)  0           batch_normalization_57[0][0]
____________________________________________________________________________________________________
conv2d_86 (Conv2D)               (None, 32, None, 13)  9248        activation_62[0][0]
____________________________________________________________________________________________________
batch_normalization_58 (BatchNor (None, 32, None, 13)  128         conv2d_86[0][0]
____________________________________________________________________________________________________
activation_63 (Activation)       (None, 32, None, 13)  0           batch_normalization_58[0][0]
____________________________________________________________________________________________________
conv2d_88 (Conv2D)               (None, 32, None, 13)  1056        add_27[0][0]
____________________________________________________________________________________________________
conv2d_87 (Conv2D)               (None, 32, None, 13)  9248        activation_63[0][0]
____________________________________________________________________________________________________
average_pooling2d_56 (AveragePoo (None, 32, None, 13)  0           conv2d_88[0][0]
____________________________________________________________________________________________________
average_pooling2d_55 (AveragePoo (None, 32, None, 13)  0           conv2d_87[0][0]
____________________________________________________________________________________________________
add_28 (Add)                     (None, 32, None, 13)  0           average_pooling2d_56[0][0]
                                                                   average_pooling2d_55[0][0]
____________________________________________________________________________________________________
batch_normalization_59 (BatchNor (None, 32, None, 13)  128         add_28[0][0]
____________________________________________________________________________________________________
activation_64 (Activation)       (None, 32, None, 13)  0           batch_normalization_59[0][0]
____________________________________________________________________________________________________
conv2d_89 (Conv2D)               (None, 32, None, 13)  9248        activation_64[0][0]
____________________________________________________________________________________________________
batch_normalization_60 (BatchNor (None, 32, None, 13)  128         conv2d_89[0][0]
____________________________________________________________________________________________________
activation_65 (Activation)       (None, 32, None, 13)  0           batch_normalization_60[0][0]
____________________________________________________________________________________________________
conv2d_91 (Conv2D)               (None, 32, None, 13)  1056        add_28[0][0]
____________________________________________________________________________________________________
conv2d_90 (Conv2D)               (None, 32, None, 13)  9248        activation_65[0][0]
____________________________________________________________________________________________________
average_pooling2d_58 (AveragePoo (None, 32, None, 13)  0           conv2d_91[0][0]
____________________________________________________________________________________________________
average_pooling2d_57 (AveragePoo (None, 32, None, 13)  0           conv2d_90[0][0]
____________________________________________________________________________________________________
add_29 (Add)                     (None, 32, None, 13)  0           average_pooling2d_58[0][0]
                                                                   average_pooling2d_57[0][0]
____________________________________________________________________________________________________
batch_normalization_61 (BatchNor (None, 32, None, 13)  128         add_29[0][0]
____________________________________________________________________________________________________
activation_66 (Activation)       (None, 32, None, 13)  0           batch_normalization_61[0][0]
____________________________________________________________________________________________________
conv2d_92 (Conv2D)               (None, 32, None, 13)  9248        activation_66[0][0]
____________________________________________________________________________________________________
batch_normalization_62 (BatchNor (None, 32, None, 13)  128         conv2d_92[0][0]
____________________________________________________________________________________________________
activation_67 (Activation)       (None, 32, None, 13)  0           batch_normalization_62[0][0]
____________________________________________________________________________________________________
conv2d_94 (Conv2D)               (None, 32, None, 13)  1056        add_29[0][0]
____________________________________________________________________________________________________
conv2d_93 (Conv2D)               (None, 32, None, 13)  9248        activation_67[0][0]
____________________________________________________________________________________________________
average_pooling2d_60 (AveragePoo (None, 32, None, 13)  0           conv2d_94[0][0]
____________________________________________________________________________________________________
average_pooling2d_59 (AveragePoo (None, 32, None, 13)  0           conv2d_93[0][0]
____________________________________________________________________________________________________
add_30 (Add)                     (None, 32, None, 13)  0           average_pooling2d_60[0][0]
                                                                   average_pooling2d_59[0][0]
____________________________________________________________________________________________________
batch_normalization_63 (BatchNor (None, 32, None, 13)  128         add_30[0][0]
____________________________________________________________________________________________________
activation_68 (Activation)       (None, 32, None, 13)  0           batch_normalization_63[0][0]
____________________________________________________________________________________________________
conv2d_95 (Conv2D)               (None, 1, None, 13)   289         activation_68[0][0]
____________________________________________________________________________________________________
lambda_10 (Lambda)               (None, None, 13)      0           conv2d_95[0][0]
____________________________________________________________________________________________________
bidirectional_5 (Bidirectional)  (None, None, 64)      11776       lambda_10[0][0]
____________________________________________________________________________________________________
soft_attention_5 (SoftAttention) (None, 64)            4224        bidirectional_5[0][0]
____________________________________________________________________________________________________
dense_9 (Dense)                  (None, 32)            2080        soft_attention_5[0][0]
____________________________________________________________________________________________________
batch_normalization_64 (BatchNor (None, 32)            128         dense_9[0][0]
____________________________________________________________________________________________________
activation_69 (Activation)       (None, 32)            0           batch_normalization_64[0][0]
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 32)            0           activation_69[0][0]
____________________________________________________________________________________________________
dense_10 (Dense)                 (None, 32)            1056        dropout_9[0][0]
____________________________________________________________________________________________________
batch_normalization_65 (BatchNor (None, 32)            128         dense_10[0][0]
____________________________________________________________________________________________________
activation_70 (Activation)       (None, 32)            0           batch_normalization_65[0][0]
____________________________________________________________________________________________________
input_14 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_15 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 32)            0           activation_70[0][0]
____________________________________________________________________________________________________
concatenate_5 (Concatenate)      (None, 34)            0           input_14[0][0]
                                                                   input_15[0][0]
                                                                   dropout_10[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_5[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_16 (InputLayer)            (None, None, 13)      0
____________________________________________________________________________________________________
masking_6 (Masking)              (None, None, 13)      0           input_16[0][0]
____________________________________________________________________________________________________
lambda_11 (Lambda)               (None, 1, None, 13)   0           masking_6[0][0]
____________________________________________________________________________________________________
conv2d_97 (Conv2D)               (None, 32, None, 13)  320         lambda_11[0][0]
____________________________________________________________________________________________________
activation_71 (Activation)       (None, 32, None, 13)  0           conv2d_97[0][0]
____________________________________________________________________________________________________
average_pooling2d_61 (AveragePoo (None, 1, None, 13)   0           lambda_11[0][0]
____________________________________________________________________________________________________
conv2d_98 (Conv2D)               (None, 32, None, 13)  9248        activation_71[0][0]
____________________________________________________________________________________________________
conv2d_96 (Conv2D)               (None, 32, None, 13)  64          average_pooling2d_61[0][0]
____________________________________________________________________________________________________
average_pooling2d_62 (AveragePoo (None, 32, None, 13)  0           conv2d_98[0][0]
____________________________________________________________________________________________________
add_31 (Add)                     (None, 32, None, 13)  0           conv2d_96[0][0]
                                                                   average_pooling2d_62[0][0]
____________________________________________________________________________________________________
batch_normalization_66 (BatchNor (None, 32, None, 13)  128         add_31[0][0]
____________________________________________________________________________________________________
activation_72 (Activation)       (None, 32, None, 13)  0           batch_normalization_66[0][0]
____________________________________________________________________________________________________
conv2d_99 (Conv2D)               (None, 32, None, 13)  9248        activation_72[0][0]
____________________________________________________________________________________________________
batch_normalization_67 (BatchNor (None, 32, None, 13)  128         conv2d_99[0][0]
____________________________________________________________________________________________________
activation_73 (Activation)       (None, 32, None, 13)  0           batch_normalization_67[0][0]
____________________________________________________________________________________________________
conv2d_101 (Conv2D)              (None, 32, None, 13)  1056        add_31[0][0]
____________________________________________________________________________________________________
conv2d_100 (Conv2D)              (None, 32, None, 13)  9248        activation_73[0][0]
____________________________________________________________________________________________________
average_pooling2d_64 (AveragePoo (None, 32, None, 13)  0           conv2d_101[0][0]
____________________________________________________________________________________________________
average_pooling2d_63 (AveragePoo (None, 32, None, 13)  0           conv2d_100[0][0]
____________________________________________________________________________________________________
add_32 (Add)                     (None, 32, None, 13)  0           average_pooling2d_64[0][0]
                                                                   average_pooling2d_63[0][0]
____________________________________________________________________________________________________
batch_normalization_68 (BatchNor (None, 32, None, 13)  128         add_32[0][0]
____________________________________________________________________________________________________
activation_74 (Activation)       (None, 32, None, 13)  0           batch_normalization_68[0][0]
____________________________________________________________________________________________________
conv2d_102 (Conv2D)              (None, 32, None, 13)  9248        activation_74[0][0]
____________________________________________________________________________________________________
batch_normalization_69 (BatchNor (None, 32, None, 13)  128         conv2d_102[0][0]
____________________________________________________________________________________________________
activation_75 (Activation)       (None, 32, None, 13)  0           batch_normalization_69[0][0]
____________________________________________________________________________________________________
conv2d_104 (Conv2D)              (None, 32, None, 13)  1056        add_32[0][0]
____________________________________________________________________________________________________
conv2d_103 (Conv2D)              (None, 32, None, 13)  9248        activation_75[0][0]
____________________________________________________________________________________________________
average_pooling2d_66 (AveragePoo (None, 32, None, 13)  0           conv2d_104[0][0]
____________________________________________________________________________________________________
average_pooling2d_65 (AveragePoo (None, 32, None, 13)  0           conv2d_103[0][0]
____________________________________________________________________________________________________
add_33 (Add)                     (None, 32, None, 13)  0           average_pooling2d_66[0][0]
                                                                   average_pooling2d_65[0][0]
____________________________________________________________________________________________________
batch_normalization_70 (BatchNor (None, 32, None, 13)  128         add_33[0][0]
____________________________________________________________________________________________________
activation_76 (Activation)       (None, 32, None, 13)  0           batch_normalization_70[0][0]
____________________________________________________________________________________________________
conv2d_105 (Conv2D)              (None, 32, None, 13)  9248        activation_76[0][0]
____________________________________________________________________________________________________
batch_normalization_71 (BatchNor (None, 32, None, 13)  128         conv2d_105[0][0]
____________________________________________________________________________________________________
activation_77 (Activation)       (None, 32, None, 13)  0           batch_normalization_71[0][0]
____________________________________________________________________________________________________
conv2d_107 (Conv2D)              (None, 32, None, 13)  1056        add_33[0][0]
____________________________________________________________________________________________________
conv2d_106 (Conv2D)              (None, 32, None, 13)  9248        activation_77[0][0]
____________________________________________________________________________________________________
average_pooling2d_68 (AveragePoo (None, 32, None, 13)  0           conv2d_107[0][0]
____________________________________________________________________________________________________
average_pooling2d_67 (AveragePoo (None, 32, None, 13)  0           conv2d_106[0][0]
____________________________________________________________________________________________________
add_34 (Add)                     (None, 32, None, 13)  0           average_pooling2d_68[0][0]
                                                                   average_pooling2d_67[0][0]
____________________________________________________________________________________________________
batch_normalization_72 (BatchNor (None, 32, None, 13)  128         add_34[0][0]
____________________________________________________________________________________________________
activation_78 (Activation)       (None, 32, None, 13)  0           batch_normalization_72[0][0]
____________________________________________________________________________________________________
conv2d_108 (Conv2D)              (None, 32, None, 13)  9248        activation_78[0][0]
____________________________________________________________________________________________________
batch_normalization_73 (BatchNor (None, 32, None, 13)  128         conv2d_108[0][0]
____________________________________________________________________________________________________
activation_79 (Activation)       (None, 32, None, 13)  0           batch_normalization_73[0][0]
____________________________________________________________________________________________________
conv2d_110 (Conv2D)              (None, 32, None, 13)  1056        add_34[0][0]
____________________________________________________________________________________________________
conv2d_109 (Conv2D)              (None, 32, None, 13)  9248        activation_79[0][0]
____________________________________________________________________________________________________
average_pooling2d_70 (AveragePoo (None, 32, None, 13)  0           conv2d_110[0][0]
____________________________________________________________________________________________________
average_pooling2d_69 (AveragePoo (None, 32, None, 13)  0           conv2d_109[0][0]
____________________________________________________________________________________________________
add_35 (Add)                     (None, 32, None, 13)  0           average_pooling2d_70[0][0]
                                                                   average_pooling2d_69[0][0]
____________________________________________________________________________________________________
batch_normalization_74 (BatchNor (None, 32, None, 13)  128         add_35[0][0]
____________________________________________________________________________________________________
activation_80 (Activation)       (None, 32, None, 13)  0           batch_normalization_74[0][0]
____________________________________________________________________________________________________
conv2d_111 (Conv2D)              (None, 32, None, 13)  9248        activation_80[0][0]
____________________________________________________________________________________________________
batch_normalization_75 (BatchNor (None, 32, None, 13)  128         conv2d_111[0][0]
____________________________________________________________________________________________________
activation_81 (Activation)       (None, 32, None, 13)  0           batch_normalization_75[0][0]
____________________________________________________________________________________________________
conv2d_113 (Conv2D)              (None, 32, None, 13)  1056        add_35[0][0]
____________________________________________________________________________________________________
conv2d_112 (Conv2D)              (None, 32, None, 13)  9248        activation_81[0][0]
____________________________________________________________________________________________________
average_pooling2d_72 (AveragePoo (None, 32, None, 13)  0           conv2d_113[0][0]
____________________________________________________________________________________________________
average_pooling2d_71 (AveragePoo (None, 32, None, 13)  0           conv2d_112[0][0]
____________________________________________________________________________________________________
add_36 (Add)                     (None, 32, None, 13)  0           average_pooling2d_72[0][0]
                                                                   average_pooling2d_71[0][0]
____________________________________________________________________________________________________
batch_normalization_76 (BatchNor (None, 32, None, 13)  128         add_36[0][0]
____________________________________________________________________________________________________
activation_82 (Activation)       (None, 32, None, 13)  0           batch_normalization_76[0][0]
____________________________________________________________________________________________________
conv2d_114 (Conv2D)              (None, 1, None, 13)   289         activation_82[0][0]
____________________________________________________________________________________________________
lambda_12 (Lambda)               (None, None, 13)      0           conv2d_114[0][0]
____________________________________________________________________________________________________
bidirectional_6 (Bidirectional)  (None, None, 64)      11776       lambda_12[0][0]
____________________________________________________________________________________________________
soft_attention_6 (SoftAttention) (None, 64)            4224        bidirectional_6[0][0]
____________________________________________________________________________________________________
dense_11 (Dense)                 (None, 32)            2080        soft_attention_6[0][0]
____________________________________________________________________________________________________
batch_normalization_77 (BatchNor (None, 32)            128         dense_11[0][0]
____________________________________________________________________________________________________
activation_83 (Activation)       (None, 32)            0           batch_normalization_77[0][0]
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 32)            0           activation_83[0][0]
____________________________________________________________________________________________________
dense_12 (Dense)                 (None, 32)            1056        dropout_11[0][0]
____________________________________________________________________________________________________
batch_normalization_78 (BatchNor (None, 32)            128         dense_12[0][0]
____________________________________________________________________________________________________
activation_84 (Activation)       (None, 32)            0           batch_normalization_78[0][0]
____________________________________________________________________________________________________
input_17 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_18 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 32)            0           activation_84[0][0]
____________________________________________________________________________________________________
concatenate_6 (Concatenate)      (None, 34)            0           input_17[0][0]
                                                                   input_18[0][0]
                                                                   dropout_12[0][0]
____________________________________________________________________________________________________
discriminator_output (Dense)     (None, 1)             35          concatenate_6[0][0]
====================================================================================================
Total params: 128,516
Trainable params: 127,684
Non-trainable params: 832
____________________________________________________________________________________________________
INFO: Loading weights of /xxx
INFO: Saved used model to /xxx
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_19 (InputLayer)            (None, 32)            0
____________________________________________________________________________________________________
input_20 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_21 (InputLayer)            (None, 32)            0
____________________________________________________________________________________________________
input_22 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_23 (InputLayer)            (None, 32)            0
____________________________________________________________________________________________________
input_24 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
concatenate_7 (Concatenate)      (None, 99)            0           input_19[0][0]
                                                                   input_20[0][0]
                                                                   input_21[0][0]
                                                                   input_22[0][0]
                                                                   input_23[0][0]
                                                                   input_24[0][0]
____________________________________________________________________________________________________
dense_13 (Dense)                 (None, 80)            8000        concatenate_7[0][0]
____________________________________________________________________________________________________
batch_normalization_79 (BatchNor (None, 80)            320         dense_13[0][0]
____________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)        (None, 80)            0           batch_normalization_79[0][0]
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 80)            0           leaky_re_lu_1[0][0]
____________________________________________________________________________________________________
dense_14 (Dense)                 (None, 64)            5184        dropout_13[0][0]
____________________________________________________________________________________________________
batch_normalization_80 (BatchNor (None, 64)            256         dense_14[0][0]
____________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)        (None, 64)            0           batch_normalization_80[0][0]
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 64)            0           leaky_re_lu_2[0][0]
____________________________________________________________________________________________________
dense_15 (Dense)                 (None, 48)            3120        dropout_14[0][0]
____________________________________________________________________________________________________
batch_normalization_81 (BatchNor (None, 48)            192         dense_15[0][0]
____________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)        (None, 48)            0           batch_normalization_81[0][0]
____________________________________________________________________________________________________
input_25 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
input_26 (InputLayer)            (None, 1)             0
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 48)            0           leaky_re_lu_3[0][0]
____________________________________________________________________________________________________
concatenate_8 (Concatenate)      (None, 50)            0           input_25[0][0]
                                                                   input_26[0][0]
                                                                   dropout_15[0][0]
____________________________________________________________________________________________________
dense_16 (Dense)                 (None, 1)             51          concatenate_8[0][0]
====================================================================================================
Total params: 17,123
Trainable params: 16,739
Non-trainable params: 384
____________________________________________________________________________________________________
Epoch 1/250
882/882 [==============================] - 1513s - loss: 0.5807 - acc: 0.7140 - val_loss: 0.5083 - val_acc: 0.7756
Epoch 2/250
882/882 [==============================] - 658s - loss: 0.5496 - acc: 0.7365 - val_loss: 0.4863 - val_acc: 0.7757
Epoch 3/250
882/882 [==============================] - 662s - loss: 0.5191 - acc: 0.7561 - val_loss: 0.4725 - val_acc: 0.7756
Epoch 4/250
882/882 [==============================] - 293s - loss: 0.5073 - acc: 0.7640 - val_loss: 0.4720 - val_acc: 0.7726
Epoch 5/250
882/882 [==============================] - 94s - loss: 0.4963 - acc: 0.7677 - val_loss: 0.4554 - val_acc: 0.7864
Epoch 6/250
882/882 [==============================] - 109s - loss: 0.4859 - acc: 0.7820 - val_loss: 0.4497 - val_acc: 0.7940
Epoch 7/250
882/882 [==============================] - 105s - loss: 0.4848 - acc: 0.7768 - val_loss: 0.4502 - val_acc: 0.7934
Epoch 8/250
882/882 [==============================] - 109s - loss: 0.4791 - acc: 0.7764 - val_loss: 0.4356 - val_acc: 0.7984
Epoch 9/250
882/882 [==============================] - 101s - loss: 0.4625 - acc: 0.7918 - val_loss: 0.4338 - val_acc: 0.8047
Epoch 10/250
882/882 [==============================] - 108s - loss: 0.4647 - acc: 0.7905 - val_loss: 0.4415 - val_acc: 0.8013
Epoch 11/250
882/882 [==============================] - 108s - loss: 0.4602 - acc: 0.7954 - val_loss: 0.4265 - val_acc: 0.8076
Epoch 12/250
882/882 [==============================] - 113s - loss: 0.4567 - acc: 0.7988 - val_loss: 0.4180 - val_acc: 0.8115
Epoch 13/250
882/882 [==============================] - 106s - loss: 0.4563 - acc: 0.7997 - val_loss: 0.4236 - val_acc: 0.8132
Epoch 14/250
882/882 [==============================] - 111s - loss: 0.4448 - acc: 0.8067 - val_loss: 0.4323 - val_acc: 0.8040
Epoch 15/250
882/882 [==============================] - 105s - loss: 0.4418 - acc: 0.8094 - val_loss: 0.4258 - val_acc: 0.8129
Epoch 16/250
882/882 [==============================] - 104s - loss: 0.4508 - acc: 0.8013 - val_loss: 0.4176 - val_acc: 0.8173
Epoch 17/250
882/882 [==============================] - 104s - loss: 0.4460 - acc: 0.8026 - val_loss: 0.4154 - val_acc: 0.8227
Epoch 18/250
882/882 [==============================] - 99s - loss: 0.4369 - acc: 0.8132 - val_loss: 0.4304 - val_acc: 0.8125
Epoch 19/250
882/882 [==============================] - 93s - loss: 0.4319 - acc: 0.8162 - val_loss: 0.4178 - val_acc: 0.8194
Epoch 20/250
882/882 [==============================] - 106s - loss: 0.4286 - acc: 0.8173 - val_loss: 0.4146 - val_acc: 0.8209
Epoch 21/250
882/882 [==============================] - 110s - loss: 0.4287 - acc: 0.8109 - val_loss: 0.4207 - val_acc: 0.8250
Epoch 22/250
882/882 [==============================] - 110s - loss: 0.4267 - acc: 0.8211 - val_loss: 0.3919 - val_acc: 0.8320
Epoch 23/250
882/882 [==============================] - 107s - loss: 0.4270 - acc: 0.8214 - val_loss: 0.4081 - val_acc: 0.8340
Epoch 24/250
882/882 [==============================] - 111s - loss: 0.4259 - acc: 0.8192 - val_loss: 0.4195 - val_acc: 0.8248
Epoch 25/250
882/882 [==============================] - 107s - loss: 0.4250 - acc: 0.8241 - val_loss: 0.4019 - val_acc: 0.8419
Epoch 26/250
882/882 [==============================] - 106s - loss: 0.4124 - acc: 0.8284 - val_loss: 0.4047 - val_acc: 0.8320
Epoch 27/250
882/882 [==============================] - 106s - loss: 0.4170 - acc: 0.8250 - val_loss: 0.4010 - val_acc: 0.8296
Epoch 28/250
882/882 [==============================] - 96s - loss: 0.4137 - acc: 0.8275 - val_loss: 0.4000 - val_acc: 0.8393
Epoch 29/250
882/882 [==============================] - 107s - loss: 0.4133 - acc: 0.8282 - val_loss: 0.3985 - val_acc: 0.8417
Epoch 30/250
882/882 [==============================] - 109s - loss: 0.4155 - acc: 0.8261 - val_loss: 0.3926 - val_acc: 0.8385
INFO: Started evaluation.
INFO: Collecting training data for 7056 samples.
INFO: Completed 500 steps.
INFO: Completed 1000 steps.
INFO: Completed 1500 steps.
INFO: Completed 2000 steps.
INFO: Completed 2500 steps.
INFO: Completed 3000 steps.
INFO: Completed 3500 steps.
INFO: Completed 4000 steps.
INFO: Completed 4500 steps.
INFO: Completed 5000 steps.
INFO: Completed 5500 steps.
INFO: Completed 6000 steps.
INFO: Completed 6500 steps.
INFO: Completed 7000 steps.
INFO: Started training evaluation ensemble.
INFO: Collecting validation data for 10080 samples.
INFO: Completed 500 steps.
INFO: Completed 1000 steps.
INFO: Completed 1500 steps.
INFO: Completed 2000 steps.
INFO: Completed 2500 steps.
INFO: Completed 3000 steps.
INFO: Completed 3500 steps.
INFO: Completed 4000 steps.
INFO: Completed 4500 steps.
INFO: Completed 5000 steps.
INFO: Completed 5500 steps.
INFO: Completed 6000 steps.
INFO: Completed 6500 steps.
INFO: Completed 7000 steps.
INFO: Completed 7500 steps.
INFO: Completed 8000 steps.
INFO: Completed 8500 steps.
INFO: Completed 9000 steps.
INFO: Completed 9500 steps.
INFO: Completed 10000 steps.
INFO: Evaluation score for model MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=60, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False) was: 0.999856774563
INFO: Evaluation score for model SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='hinge', max_iter=60, n_iter=None,
       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, tol=None, verbose=0, warm_start=False) was: 0.991907762819
INFO: Evaluation score for model KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform') was: 0.992623890003
INFO: Evaluation score for model SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False) was: 0.999856774563
INFO: Evaluation score for model RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=48, n_jobs=1,
            oob_score=False, random_state=999, verbose=0, warm_start=False) was: 1.0
INFO: Average AUC was: 0.99684904039 (on 10080 samples).

